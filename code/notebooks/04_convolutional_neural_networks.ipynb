{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LOa3gmeXyEU"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "luWKEVoPXzsy"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVPFWCBSa2u8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models, utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Jy4a84UsPNTd",
    "outputId": "dec0ac31-cbd6-403b-d6cf-2324a573cc2c"
   },
   "outputs": [],
   "source": [
    "# Need to get Google Drive access\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxhvI4bBPPq9"
   },
   "outputs": [],
   "source": [
    "# Load the dataset into a Pandas dataframe\n",
    "img_dir = os.path.join('/content/gdrive/My Drive/data/breast_cancer_nuclei/patches_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TEvKmqta9Wi"
   },
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "# Training and testing batch size\n",
    "args[\"train_batch_size\"] = 8 # 64\n",
    "args[\"test_batch_size\"] = 8 # 1000\n",
    "\n",
    "# How long to train for\n",
    "args[\"epochs\"] = 2 # 100\n",
    "\n",
    "# Learning rate: \"Speed\" with which the optimizer adjusts weights\n",
    "args[\"lr\"] = 0.01\n",
    "\n",
    "# Momentum: How quickly the weights respond to changing gradients\n",
    "args[\"momentum\"] = 0.5\n",
    "\n",
    "# Whether to use CUDA or not\n",
    "args[\"no_cuda\"] = False\n",
    "\n",
    "# Seed for reproducible training\n",
    "args[\"seed\"] = 1\n",
    "\n",
    "# How often to spit out log / progress updates\n",
    "args[\"log_interval\"] = 10\n",
    "\n",
    "# Whether to save the trained model\n",
    "args[\"save_model\"] = False\n",
    "\n",
    "# Decide whether to use CUDA\n",
    "use_cuda = not args[\"no_cuda\"] and torch.cuda.is_available()\n",
    "\n",
    "# Set the seed\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "# Select the device to use based on the `use_cuda` flag\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Keyword arguments for the dataloader\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6IW6LFkbHmZ"
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose(\n",
    "    [transforms.Resize(64),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "nuclei_trainset = datasets.ImageFolder(root=os.path.join(img_dir, 'train'), transform=data_transform)\n",
    "nuclei_testset = datasets.ImageFolder(root=os.path.join(img_dir, 'test'), transform=data_transform)\n",
    "\n",
    "nuclei_trainloader = torch.utils.data.DataLoader(nuclei_trainset, batch_size=args['train_batch_size'],\n",
    "                                                 shuffle=True, num_workers=2)\n",
    "nuclei_testloader = torch.utils.data.DataLoader(nuclei_trainset, batch_size=args['test_batch_size'],\n",
    "                                                 shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('nonnuclei', 'nuclei')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s3qhJ2ZQO8Nt"
   },
   "source": [
    "## Visualize Some Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66kTn_0jO-W9"
   },
   "outputs": [],
   "source": [
    "def imshow(images):\n",
    "    img_grid = utils.make_grid(images)\n",
    "    img = img_grid / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1QWH5nGkX1yA"
   },
   "source": [
    "# Data Description and Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e36_LBKDX44Q"
   },
   "source": [
    "# Data Visualization and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "id": "z4KwDI5DPBbE",
    "outputId": "58cdb1f2-f80f-49ae-d21c-d9cabbd91455"
   },
   "outputs": [],
   "source": [
    "# Get some random training images (one iteration of the dataloader)\n",
    "dataiter = iter(nuclei_trainloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(images)\n",
    "\n",
    "# Print the associated labels\n",
    "print('\\t' + '\\t\\t'.join('%5s' % classes[labels[j]] for j in range(args['train_batch_size'])))\n",
    "print(' ')\n",
    "print('The size of the image batch is: {}'.format(images.shape))\n",
    "print('This represents (batch_size, channels, height, width)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-DvQRB1QP_U"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaB-WiRDQRTV"
   },
   "outputs": [],
   "source": [
    "class NucleiNet(nn.Module):\n",
    "    def __init__(self, disp_size):\n",
    "        super(NucleiNet, self).__init__()\n",
    "        \n",
    "        # Flag whether or not to print out information about the tensor\n",
    "        self.disp_size = disp_size\n",
    "        \n",
    "        # nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, 1, 1)\n",
    "        \n",
    "        # nn.MaxPool2d(kernel_size, stride)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1, 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # nn.Linear(in_features, out_features)\n",
    "        self.fc1 = nn.Linear(16 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, 120)\n",
    "        self.fc3 = nn.Linear(120, 84)\n",
    "        self.fc4 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.disp_size:\n",
    "            print('x input size:\\t\\t\\t\\t\\t{}'.format(x.shape))\n",
    "\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        if self.disp_size:\n",
    "            print('After first block [Conv->Relu->Pool]:\\t\\t{}'.format(x.shape))\n",
    "        \n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        if self.disp_size:\n",
    "            print('After second block [Conv->Relu->Pool]:\\t\\t{}'.format(x.shape))\n",
    "\n",
    "        x = x.view(-1, 16 * 16 * 16)\n",
    "        if self.disp_size:\n",
    "            print('After reshape:\\t\\t\\t\\t\\t{}'.format(x.shape))\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if self.disp_size:\n",
    "            print('After first linear layer:\\t\\t\\t{}'.format(x.shape))\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        if self.disp_size:\n",
    "            print('After second linear layer:\\t\\t\\t{}'.format(x.shape))\n",
    "            \n",
    "        x = F.relu(self.fc3(x))\n",
    "        if self.disp_size:\n",
    "            print('After third linear layer:\\t\\t\\t{}'.format(x.shape))\n",
    "            \n",
    "        x = self.fc4(x)\n",
    "        if self.disp_size:\n",
    "            print('After fourth linear layer:\\t\\t\\t{}'.format(x.shape))\n",
    "            print(' ')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ouXM5TvcFhVI"
   },
   "source": [
    "## Model Interrogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "fPu-oS7hQaaZ",
    "outputId": "ad9715b9-7f0d-4b70-90fd-d4cc93bf14e8"
   },
   "outputs": [],
   "source": [
    "# Create a model and set the \"disp_size\" to True, so it will print out the size of each layer\n",
    "nuclei_net = NucleiNet(disp_size=True)\n",
    "\n",
    "# Run an image batch through just to get some output\n",
    "_ = nuclei_net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "PoZhOd3eYWKI",
    "outputId": "713e2cda-99b2-4f6f-e843-c7ca6a22c781"
   },
   "outputs": [],
   "source": [
    "# In PyTorch you can list out the different layers as \"children\" of the model\n",
    "list(nuclei_net.children())[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "xtmoqQdKQe0-",
    "outputId": "0748d17e-b561-419b-b6ff-0ed914084723"
   },
   "outputs": [],
   "source": [
    "# You can also pull out specific layers of the model and use them to build a new one\n",
    "# Here we look at the first four layers, which include the two convolutional and pooling layers\n",
    "nuclei_features = nn.Sequential(*list(nuclei_net.children())[0:4])\n",
    "\n",
    "print(\"First three layers:\")\n",
    "print(nuclei_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzRFqPE0FnnM"
   },
   "source": [
    "## Visualizing Filter Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "635G13q7Qk8M",
    "outputId": "ff121f77-c893-4b83-e70d-1847a8dcd3b1"
   },
   "outputs": [],
   "source": [
    "outputs = nuclei_features(images)\n",
    "print(\"size of outputs: {}\".format(outputs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 946
    },
    "colab_type": "code",
    "id": "C8nY42txQqHk",
    "outputId": "e93c26b3-076b-4c33-ba07-a49872337fda"
   },
   "outputs": [],
   "source": [
    "# Which image in the batch do you want to look at?\n",
    "target_img = 0\n",
    "\n",
    "# Set up the filter block\n",
    "num_channels = outputs.shape[0]\n",
    "\n",
    "# Set up the display of the filter block for this image\n",
    "rows = int(np.floor(np.sqrt(num_channels)))\n",
    "if np.mod(np.sqrt(num_channels), 1) != 0:\n",
    "    # There is a remainder\n",
    "    cols = rows + 1\n",
    "else:\n",
    "    cols = rows\n",
    "\n",
    "# Plot the original\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "plt.imshow(np.transpose(images[target_img].cpu() / 2 + 0.5, (1,2,0)))\n",
    "plt.title('Original image')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "output_numpy = outputs[target_img,:,:,:].detach().cpu()\n",
    "\n",
    "fig, ax = plt.subplots(rows,cols, figsize=(10,10))\n",
    "\n",
    "for i, r in enumerate(ax):\n",
    "    for j, c in enumerate(r):\n",
    "        c.imshow(output_numpy[i*cols+j,:,:], cmap=plt.cm.gray)\n",
    "        c.set_title('Filter {}'.format(i*cols+j))\n",
    "        c.axis('off')\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jWaTCHIQ0W6"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m3WZFuJ3Q08y",
    "outputId": "c15bdb3a-a11e-4364-cb32-8b0137acca96"
   },
   "outputs": [],
   "source": [
    "nuclei_net = NucleiNet(disp_size=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "# move model to the right device\n",
    "nuclei_net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(nuclei_net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "2-O6K4kaQ_Gz",
    "outputId": "9f65f46d-7e39-4684-82c9-e7f244b58c7c"
   },
   "outputs": [],
   "source": [
    "list_loss = []\n",
    "avg_loss = []\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(nuclei_trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        #inputs, labels = data\n",
    "\n",
    "        # Move to the GPU\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = nuclei_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            list_loss.append(running_loss / 20)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Record average loss for this epoch\n",
    "    avg_loss.append(np.mean(list_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "rE7IEjyFRCfo",
    "outputId": "b0860eff-e319-4414-bf71-f042ceb08d74"
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "q8EXvIYxVCPP",
    "outputId": "99e8738e-add8-430c-eb51-4b4cf31daaf5"
   },
   "outputs": [],
   "source": [
    "#dataiter = iter(nuclei_testloader)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "outputs = nuclei_net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# print images\n",
    "imshow(images.cpu())\n",
    "print('GroundTruth: ', ' '.join('\\t%5s' % classes[labels[j]] for j in range(args['test_batch_size'])))\n",
    "print('Predicted: ', ' '.join('\\t%5s' % classes[predicted[j]]\n",
    "                              for j in range(args['test_batch_size'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WuLDK0TfVwRH",
    "outputId": "1f08970c-2043-41ba-da1b-a400196af105"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in nuclei_testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = nuclei_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the {} testing images: {} %'.format(\n",
    "    total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ktcV4yLNV1JO",
    "outputId": "ae9b13b9-62c6-40fd-af6f-e11cb37dd2d8"
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(3))\n",
    "class_total = list(0. for i in range(3))\n",
    "with torch.no_grad():\n",
    "    for data in nuclei_testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = nuclei_net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(2):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of {} : {} %'.format(\n",
    "        classes[i], \n",
    "        100.0 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIulxB3GIWRI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4LOa3gmeXyEU",
    "luWKEVoPXzsy",
    "s3qhJ2ZQO8Nt",
    "1QWH5nGkX1yA",
    "e36_LBKDX44Q",
    "s-DvQRB1QP_U",
    "ouXM5TvcFhVI",
    "XzRFqPE0FnnM",
    "1jWaTCHIQ0W6"
   ],
   "name": "04-convolutional-neural-networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
