{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains code that is useful in performing image analysis.\n",
    "\n",
    "We first demonstrate how to deal with WSIs using both OpenSlide and BioFormats.\n",
    "\n",
    "We are using a `.svs` file from The Cancer Genome Atlas for demonstration, as well as a `.vsi` file from our database. \n",
    "\n",
    "These will NOT be included with the notebook by default, so you'll have to grab some WSI from someone to test out the same routines as in this book.\n",
    "Alternatively, if you're just using this as a reference, you should be able to copy-paste the relevant bits to your own code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With WSIs: Openslide\n",
    "\n",
    "To install openslide on a Mac, do `brew install openslide` followed by `pip install openslide-python`. Simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openslide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening a Slide, Looking at Parameters\n",
    "\n",
    "The [OpenSlide API](http://openslide.org/api/python/) doesn't have extensive documentation, but it does have a lot of the properties we'd need for loading up the `scn` files from Leica. \n",
    "\n",
    "The following opens a handle to an `openslide` class instance which provides the associated metadata (via properties) and loading (through the `read_region()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join('data', 'TCGA-AD-6899-01Z-00-DX1.646f5e1a-212f-4b15-8689-8b55f7ba8c47.svs')\n",
    "#img_path = os.path.join('data', 'TCGA-A6-6654-01Z-00-DX1.ed491b61-7c44-4275-879b-22f8007b5ff1.svs')\n",
    "\n",
    "img_slide = openslide.OpenSlide(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the features of the slide scan\n",
    "scan_properties = img_slide.properties\n",
    "scan_levels = img_slide.level_count\n",
    "scan_dimensions = img_slide.dimensions\n",
    "scan_level_dimensions = img_slide.level_dimensions\n",
    "scan_level_downsamples = img_slide.level_downsamples\n",
    "\n",
    "print('Scan Levels: {}'.format(scan_levels))\n",
    "print('Scan Dimensions: {}'.format(scan_dimensions))\n",
    "print('Scan Level Dimensions: {}'.format(scan_level_dimensions))\n",
    "print('Scan Level Downsamples: {}'.format(scan_level_downsamples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also skim through all the properties of the slide. \n",
    "Note that these come in two forms: First, a set of metadata and properties associated with the scanner (e.g. `aperio.PropertyName`), and second, a set of OpenSlide-specific parameters (`openslide.parameter`). \n",
    "According to the documentation, this is in the form of a mapping, which is a dict-like object -- I'm not sure what that entails but you can use `.items()` on it and dot-notation to get the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out all the properties associated with this slide\n",
    "for k, v in img_slide.properties.items():\n",
    "    print('{}: {}'.format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a Level to Work With\n",
    "\n",
    "Openslide gives us a `get_thumbnail()` method, but the way the scanners work, this might not translate into the full scan height / width.\n",
    "\n",
    "Instead we can load up an intermediate pyramidal level, in case we want to do tissue finding.\n",
    "The code below will allow you to sort and select the correct tissue level (useful in case the levels aren't inherently ordered by size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image dims associated with an intermediate-sized level\n",
    "widths, heights = zip(*scan_level_dimensions)\n",
    "idx = np.argsort(heights)\n",
    "\n",
    "# Take the middle index; fix this later if you want a specific size or level\n",
    "#intermediate_idx = idx[int(len(idx)/2)]\n",
    "intermediate_idx = 2\n",
    "int_width = scan_level_dimensions[intermediate_idx][0]\n",
    "int_height = scan_level_dimensions[intermediate_idx][1]\n",
    "\n",
    "print('intermediate index value: {}'.format(intermediate_idx))\n",
    "print('width: {}'.format(int_width))\n",
    "print('height: {}'.format(int_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Image\n",
    "\n",
    "The openslide `read_region()` method seems to be the easiest way to get at a particular level. \n",
    "To get the whole thing, give the origin as (0,0) and the width / height from the `scan_level_dimensions` property we extracted earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tile = img_slide.read_region((0,0), intermediate_idx, (int_width, int_height))\n",
    "\n",
    "# Remove the alpha channel, if there is one\n",
    "img_tile = np.array(img_tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if img_tile.shape[2] > 3:\n",
    "    img_tile = img_tile[:,:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with WSIs: BioFormats\n",
    "\n",
    "Because life is hard, sometimes Openslide doesn't work. We can try using the [Python Bioformats](https://pythonhosted.org/python-bioformats/) extension instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import javabridge\n",
    "import bioformats\n",
    "\n",
    "# Bioformats is written in Java, so we need a bridge to run the commands\n",
    "javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "# The OMEXML doesn't have user-friendly documentation, \n",
    "# so it can be useful to look at the methods and properties directly\n",
    "# See: https://stackoverflow.com/questions/1911281/how-do-i-get-list-of-methods-in-a-python-class\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing an Image Object and Looking at Metadata\n",
    "\n",
    "The metadata in bioformats is XML-formatted.\n",
    "The `get_omexml_metadata()` function will return a string of XML, which you can then parse using `OMEXML()`.\n",
    "The result is a bioformats metadata object.\n",
    "\n",
    "The documentation for the bioformats API leaves a lot to be desired, but you can look through the **[OME XML schema](https://www.openmicroscopy.org/Schemas/Documentation/Generated/OME-2016-06/ome.html)** to get an idea of what you can do with these objects.\n",
    "\n",
    "It may also help to look at **[the source for the OMEXML class](https://pythonhosted.org/python-bioformats/_modules/bioformats/omexml.html#OMEXML.Image)** to get an idea of what kinds of methods are available.\n",
    "\n",
    "I've also included the `inspect` module code to look at the various properties and methods associated with the object, but you have to play around with them to see which ones give you what you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image path\n",
    "img_path = os.path.join('data', 'wsi_occ', 'OCC-01-0008-01Z-01-O01.vsi')\n",
    "\n",
    "# Grab the metadata as OME-XML\n",
    "img_xml = bioformats.get_omexml_metadata(path=img_path)\n",
    "\n",
    "# Read in the XML with methods to get and set properties\n",
    "img_metadata = bioformats.OMEXML(img_xml)\n",
    "\n",
    "# Look at the members to see what you can do with this object\n",
    "#inspect.getmembers(img_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Full Resolution Image Index\n",
    "\n",
    "There's probably an easier way to find this, but the order of the images in the XML is not guaranteed. So here, we cycle through the number of images for this WSI and try to find the one with the largest pixel size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the number of images described by this metadata\n",
    "img_count = img_metadata.get_image_count()\n",
    "\n",
    "# Keep track of each index's pixel size\n",
    "pixel_counts = np.zeros(img_count)\n",
    "\n",
    "for img_idx in range(img_count):\n",
    "    pixel_counts[img_idx] = img_metadata.image(img_idx).Pixels.SizeX * img_metadata.image(img_idx).Pixels.SizeY\n",
    "    \n",
    "# Get the sorted indices\n",
    "pixel_idxes = np.argsort(pixel_counts)\n",
    "target_idx = pixel_idxes[-1]\n",
    "\n",
    "print('Index of the largest image: {}'.format(target_idx))\n",
    "\n",
    "# Pull out the image corresponding to the largets index\n",
    "img_object = img_metadata.image(target_idx)\n",
    "img_rows = img_object.Pixels.SizeX\n",
    "img_cols = img_object.Pixels.SizeY\n",
    "print('Rows: {}, Columns: {}'.format(img_rows, img_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Pixel Data\n",
    "\n",
    "After you figure out the image you want, there are two ways to access the pixel data: \n",
    "\n",
    "- Using the `bioformats.ImageReader()` class, and\n",
    "- Using the `bioformats.load_image()` convenience function.\n",
    "\n",
    "Main difference is that the first way allows you to read in a portion of the image -- good for tiling or reading in annotated areas. Downside is that you need to create a context object as shown below (e.g. `with bioformats.ImageReader(path) as reader:`). \n",
    "\n",
    "`bioformats.load_image` seems to avoid this, but I don't think there's a way to grab only a part of the image -- you have to load the whole thing. \n",
    "Not feasible for large images.\n",
    "\n",
    "The result, in both cases, is a straightforward `np.ndarray` object.\n",
    "Also note that in both cases, you need to pass in a `series` parameter which indicates the index of the image you want to load (this can be used to grab the highest-resolution image, as detected above, or it can be used to grab a smaller thumbnail-sized image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the bioformats imagereader to open up access to \n",
    "with bioformats.ImageReader(img_path) as reader:\n",
    "    img_tile = reader.read(series=target_idx, XYWH=(int(img_rows/2),int(img_cols/2),1000,1000))\n",
    "\n",
    "    # Adjust the color channels for OCC ROIs\n",
    "    #img_tile = img_tile[...,::-1]\n",
    "    print('Img tile size: {}'.format(img_tile.shape))\n",
    "    print('Type: {}'.format(type(img_tile)))\n",
    "    plt.imshow(img_tile)\n",
    "    plt.show()\n",
    "    reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, use the convenience function to directly load the image\n",
    "# Note this will only open a max size image of 2GB with the following warning:\n",
    "#\n",
    "## JavaException: Image plane too large. Only 2GB of data can be extracted at one time. You can workaround the problem by opening the plane in tiles; for further details, see: https://docs.openmicroscopy.org/bio-formats/5.9.0/about/bug-reporting.html#common-issues-to-check\n",
    "\n",
    "#img_full = bioformats.load_image(img_path, series=max_idx)\n",
    "#img = img_full[int(img_rows/2)-250:int(img_rows/2)+250,int(img_cols/2)-250:int(img_cols/2)+250,:]\n",
    "\n",
    "# For OCC ROIs, roll the channel axis\n",
    "#img = img[...,::-1]\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(12,12))\n",
    "#ax.imshow(img)\n",
    "#ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Image Processing\n",
    "\n",
    "This section will run through some basic image processing using any `numpy`-style image array.\n",
    "\n",
    "Using code from [the scikit-image docs](https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_ihc_color_separation.html#sphx-glr-auto-examples-color-exposure-plot-ihc-color-separation-py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Deconvolution for Pathology Stain Separation\n",
    "\n",
    "See the [scikit-image gallery example](https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_ihc_color_separation.html#sphx-glr-auto-examples-color-exposure-plot-ihc-color-separation-py) as well as [documentation for stain separation](https://scikit-image.org/docs/stable/api/skimage.color.html#skimage.color.separate_stains) for a list of the different convolutional matrices you can import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import separate_stains, hed_from_rgb\n",
    "\n",
    "img_separated = separate_stains(img_tile, hed_from_rgb)\n",
    "img_hema = img_separated[:,:,0]\n",
    "img_eosin = img_separated[:,:,1]\n",
    "img_dab = img_separated[:,:,2]\n",
    "\n",
    "# Display\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20,10))\n",
    "ax[0].imshow(img_tile)\n",
    "ax[0].set_title('Original')\n",
    "ax[1].imshow(img_hema, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Hematoxylin')\n",
    "ax[2].imshow(img_eosin, cmap=plt.cm.gray)\n",
    "ax[2].set_title('Eosin')\n",
    "ax[3].imshow(img_dab, cmap=plt.cm.gray)\n",
    "ax[3].set_title('DAB')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Regional Maxima\n",
    "\n",
    "This is something you often need to do if you've got brightish objects that you want to segment, but you can't simply threshold them.\n",
    "In this case let's try to segment the results of color deconvolution to find the nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import img_as_float\n",
    "from scipy.ndimage import gaussian_filter\n",
    "#from scipy.ndimage import binary_opening, binary_closing\n",
    "\n",
    "from skimage.morphology import reconstruction\n",
    "\n",
    "# Convert image to a float for subtraction from the original\n",
    "img_nuc = img_as_float(img_hema)\n",
    "\n",
    "# Run a simple gaussian filter to blur the image\n",
    "img_nuc = gaussian_filter(img_nuc, 1)\n",
    "\n",
    "# Create a reconstruction of the image where low-intensity \n",
    "# regions in a neighborhood are suppressed\n",
    "\n",
    "# First create a \"seed\": a matrix with the minimum value of the image\n",
    "seed = img_nuc - 0.125\n",
    "\n",
    "# Next create a \"mask\": Just the image itself\n",
    "mask = img_nuc\n",
    "\n",
    "# Create a \"dilated\" image: reconstruction through dilation\n",
    "dilated = reconstruction(seed, mask, method='dilation')\n",
    "\n",
    "img_nuc_filtered = img_nuc - dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1,\n",
    "                       ncols=3,\n",
    "                       figsize=(20, 10),\n",
    "                       sharex=True,\n",
    "                       sharey=True)\n",
    "\n",
    "ax[0].imshow(img_nuc, cmap='gray')\n",
    "ax[0].set_title('original image')\n",
    "\n",
    "ax[1].imshow(dilated, vmin=img_nuc.min(), vmax=img_nuc.max(), cmap='gray')\n",
    "ax[1].set_title('dilated')\n",
    "\n",
    "ax[2].imshow(img_nuc_filtered, cmap='gray')\n",
    "ax[2].set_title('image - dilated')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Segmentation\n",
    "\n",
    "Thresholding is simple and easy, but requires hard-coding in a value to use for the image (or for all images).\n",
    "\n",
    "Otsu's method is also simple, but uses a histogram of the image to make the threshold -- slightly more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "img_thresholded = img_nuc_filtered > 0.02\n",
    "img_otsu = img_nuc_filtered > filters.threshold_otsu(img_nuc_filtered)\n",
    "\n",
    "# Display\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 10), sharey=True)\n",
    "\n",
    "ax[0].imshow(img_nuc_filtered, cmap='gray')\n",
    "ax[0].set_title('filtered image')\n",
    "\n",
    "ax[1].imshow(img_thresholded,  cmap='gray')\n",
    "ax[1].set_title('simple threshold')\n",
    "\n",
    "ax[2].imshow(img_otsu, cmap='gray')\n",
    "ax[2].set_title('otsu thresholded image')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Cleanup: Area Filtering\n",
    "\n",
    "THere are two convenience functions in `skimage.morphology`: `remove_small_objects` and `remove_small_holes`, which should be self-evident what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import remove_small_objects, remove_small_holes\n",
    "\n",
    "img_open = remove_small_objects(img_otsu, min_size=64)\n",
    "img_close = remove_small_holes(img_open, area_threshold=64)\n",
    "\n",
    "# Display\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 10), sharey=True)\n",
    "\n",
    "ax[0].imshow(img_otsu, cmap='gray')\n",
    "ax[0].set_title('Otsu thresholded image')\n",
    "\n",
    "ax[1].imshow(img_open,  cmap='gray')\n",
    "ax[1].set_title('small objects removed')\n",
    "\n",
    "ax[2].imshow(img_close, cmap='gray')\n",
    "ax[2].set_title('small holes filled')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Replace img_nuc_bin with the final step of processing for the next section\n",
    "img_nuc_bin = img_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Labeling: Watershed\n",
    "\n",
    "Once you get a binary image separated from the original, it's time to figure out which objects should be pulled apart as separate things.\n",
    "For regular oval objects, we typically turn towards watershed -- but this can be tricky to actually code up and minimize noise.\n",
    "\n",
    "Here is the process:\n",
    "\n",
    "- Get the inverse of the Euclidean distance transform of the binary image\n",
    "- Set the background to a very negative number (so you have a \"lip\" around the border with basins inside each blob)\n",
    "- Suppress local minima to \"even out\" the catchment basis and provide a smooth interior segmentation (protect against oversegmentation)\n",
    "- Run watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.ndimage import generate_binary_structure, grey_dilation\n",
    "from skimage.morphology import watershed, label\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.color import label2rgb\n",
    "from skimage.segmentation import clear_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the euclidean distance transform -- distance from each object-pixel to the background\n",
    "img_distance = -distance_transform_edt(img_nuc_bin)\n",
    "\n",
    "# Set the background to a very negative number\n",
    "img_distance[~img_nuc_bin] = -100\n",
    "\n",
    "# Plot the distance map\n",
    "fig, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "ax.imshow(img_distance)\n",
    "ax.axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress local minima in the image to prevent over-segmentation\n",
    "# See: https://github.com/janelia-flyem/gala/blob/master/gala/morpho.py\n",
    "\n",
    "# The height threshold is determined empirically, based on distances of the objects in the image\n",
    "hthreshold = 1\n",
    "maxval = img_distance.max()\n",
    "\n",
    "img_inv = maxval - img_distance.astype(float)\n",
    "\n",
    "marker = img_inv - hthreshold\n",
    "\n",
    "mask = img_inv\n",
    "\n",
    "sel = generate_binary_structure(marker.ndim, 1)\n",
    "diff = True\n",
    "while diff:\n",
    "    markernew = grey_dilation(marker, footprint=sel)\n",
    "    markernew = np.minimum(markernew, mask)\n",
    "    diff = (markernew - marker).max() > 0\n",
    "    marker = markernew\n",
    "\n",
    "filled = maxval - marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "ax.imshow(filled)\n",
    "ax.axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform watershed\n",
    "labels_ws = watershed(filled, mask=img_nuc_bin, watershed_line=True)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,10), sharey=True)\n",
    "\n",
    "ax[0].imshow(img_nuc_bin, cmap='gray')\n",
    "ax[0].set_title('Binary Nuclear Image')\n",
    "\n",
    "ax[1].imshow(label2rgb(labels_ws, bg_label=0))\n",
    "ax[1].set_title('Watershed Segmentation')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
